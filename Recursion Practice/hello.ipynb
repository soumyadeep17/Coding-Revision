{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '3 3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16104/1778000616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdict_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdict_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '3 3'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "x  = int(input())\n",
    "dict_1 = defaultdict(list)\n",
    "dict_2 = defaultdict(list)\n",
    "\n",
    "for i in range(x[0]):\n",
    "    dict_1[i] = input()\n",
    "\n",
    "for i in range(x[1]):\n",
    "    dict_1[i] = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 31, 64]\n",
      "[11, 31, 64]\n"
     ]
    }
   ],
   "source": [
    "# arr = [3,5453,464,564,6475,7]\n",
    "arr = [64,31,11]\n",
    "def partition(arr1,i,j):\n",
    "    pivot = arr1[i] # Considering Pivot element as the first element\n",
    "    k = i+1\n",
    "    while(k<j):\n",
    "        if arr1[k] >= pivot and arr1[j] <= pivot:\n",
    "            arr1[k],arr1[j] = arr1[j],arr1[k]\n",
    "            k+=1\n",
    "            j-=1\n",
    "        elif arr1[k] > pivot and arr1[j] > pivot:\n",
    "            j-=1\n",
    "        elif arr1[k] < pivot and arr1[j] < pivot:\n",
    "            k+=1\n",
    "        else:\n",
    "            k+=1\n",
    "            j-=1\n",
    "    if arr1[i]>arr1[j]:\n",
    "        arr1[i],arr1[j] = arr1[j],arr1[i]\n",
    "    return arr1\n",
    "\n",
    "# def quickSort(arr, low, high):\n",
    "# \tif len(arr) == 1:\n",
    "# \t\treturn arr\n",
    "# \tif low < high:\n",
    "# \t\tpi = partition(arr, low, high)\n",
    "# \t\tquickSort(arr, low, pi-1)\n",
    "# \t\tquickSort(arr, pi+1, high)\n",
    "\n",
    "print(partition(arr,0,len(arr)-1))\n",
    "# quickSort(arr, 0, len(arr)-1)\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = [3,5453,464,564,6475,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 35, 45, 53, 53, 345, 435, 534, 534, 543, 5345]\n"
     ]
    }
   ],
   "source": [
    "arr = [4,35,435,45,345,3,534,53,534,53,543,5345]\n",
    "def partition(arr1,i,j):\n",
    "    pivot = arr1[i] # Considering Pivot element as the first element\n",
    "    k = i+1\n",
    "    while(k<=j):\n",
    "        if arr1[k] > pivot and arr1[j] < pivot:\n",
    "            arr1[k],arr1[j] = arr1[j],arr1[k]\n",
    "            k+=1\n",
    "            j-=1\n",
    "        elif arr1[k] > pivot and arr1[j] > pivot:\n",
    "            j-=1\n",
    "        elif arr1[k] < pivot and arr1[j] < pivot:\n",
    "            k+=1\n",
    "        else:\n",
    "            k+=1\n",
    "            j-=1\n",
    "   \n",
    "    if arr1[i]>arr1[j]:\n",
    "        arr1[i],arr1[j] = arr1[j],arr1[i]\n",
    "    return j\n",
    "    # else:\n",
    "    #     print(arr1,i,k,j)\n",
    "    #     return i\n",
    "\n",
    "def quickSort(arr,low,high):\n",
    "    if low<high:\n",
    "        pi = partition(arr, low, high)\n",
    "        quickSort(arr, low, pi-1)\n",
    "        quickSort(arr, pi+1, high)\n",
    "quickSort(arr,0,len(arr)-1)\n",
    "# print(partition(arr,0,len(arr)-1))\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "num = [4,5,6]   \n",
    "target = 6\n",
    "def bin_search(num,start,end,target):\n",
    "    if start == end:\n",
    "        if num[start] == target:\n",
    "            return start\n",
    "        else:\n",
    "            return -1\n",
    "    mid = (end + start)//2 # 3\n",
    "    if bin_search(num,start,mid,target) == -1:\n",
    "        return bin_search(num,mid+1,end,target)\n",
    "    else:\n",
    "        return bin_search(num,start,mid,target)\n",
    "print(bin_search(num,0,len(num)-1,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [4,2,21,24,2]\n",
    "def find_max(arr,start,end):\n",
    "    if (end - start == 1 or start == end):\n",
    "        return max(arr[start],arr[end])\n",
    "    else:\n",
    "        mid = (start + end) //2 #--> 2\n",
    "        return max(find_max(arr,start,mid),find_max(arr,mid+1,end))\n",
    "find_max(arr,0,len(arr)-1)\n",
    "\n",
    "# not optimal bas dekhne me acha lagra hain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abaca\n"
     ]
    }
   ],
   "source": [
    "# 'Remove Consecutive Duplicates and replace single in string using recursion'\n",
    "\n",
    "string = 'abbaca'\n",
    "def remove_dup(s,n):\n",
    "    new_s = string[0]\n",
    "    for i in range(1,n):\n",
    "        if s[i] not in new_s or s[i]!=s[i-1]:\n",
    "            new_s+=s[i]\n",
    "    return new_s\n",
    "\n",
    "print(remove_dup(string,len(string)))\n",
    "# convert string to int using recursion\n",
    "def atoi(s):\n",
    "    if len(s) == 1:\n",
    "        if s.isnumeric():\n",
    "            return s\n",
    "        else:\n",
    "            return ''\n",
    "    if s[0].isnumeric() or s[0] == '-':\n",
    "        return s[0] + atoi(s[1:])\n",
    "    return atoi(s[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4], [5, 6], [7, 8]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Intervals\n",
    "\n",
    "a = [[1,4],[5,6],[7,8]]\n",
    "def merge_interval(x):\n",
    "    if len(x) == 1:\n",
    "        return x\n",
    "    if x[0][1]>=x[1][0]:\n",
    "        return merge_interval([[x[0][0],x[1][1]]] + x[2:])\n",
    "    return [x[0]] + merge_interval(x[1:])\n",
    "merge_interval(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakINdex(arr,start,end):\n",
    "    if start == end:\n",
    "        return start\n",
    "    mid = start + (end - start)//2\n",
    "    if arr[mid]>arr[mid+1]:\n",
    "            return peakINdex(arr,0,mid)\n",
    "    if arr[mid]<arr[mid+1]:\n",
    "        return peakINdex(arr,mid+1,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicates(s):\n",
    "    if len(s) == 1:\n",
    "        return s[0]\n",
    "    if s[0] == s[1]:\n",
    "        return removeDuplicates(s[2:]) \n",
    "    if s[0]!=s[1]:\n",
    "        new_s = s[0] + removeDuplicates(s[1:])\n",
    "        return removeDuplicates(new_s)\n",
    "        \n",
    "\n",
    "removeDuplicates('abbaca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if an array is sorted or not using recursion(1: normal ,2: binary)\n",
    "def isSorted(arr):\n",
    "    if len(arr) == 1:\n",
    "        return True\n",
    "    if arr[0]>arr[1]:\n",
    "        return False\n",
    "    return isSorted(arr[1:])\n",
    "def isSorted_bin(arr):\n",
    "    mid = (len(arr)-1)//2\n",
    "    if len(arr) == 1 or (len(arr) == 2 and arr[0]<arr[1]):\n",
    "        return True\n",
    "    if arr[mid]>=arr[mid-1] and arr[mid]<=arr[mid+1]:\n",
    "        return isSorted_bin(arr[0:mid]) and isSorted_bin(arr[mid+1:])\n",
    "    else:\n",
    "        return False\n",
    "isSorted_bin([1,2,2,4,5])\n",
    "\n",
    "# [1,2,8,10,11,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.01606369018555\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "isSorted([i for  i in range(1000)])\n",
    "t2 = time.time()\n",
    "print((t2-t1)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612.3147010803223\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "isSorted_bin([i for  i in range(1000000)])\n",
    "t2 = time.time()\n",
    "print((t2-t1)*1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([1,0,1])^np.array([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1]\n",
      "[0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "length = 5\n",
    "a = [0]*length\n",
    "for i in range(0,length,2):\n",
    "    a[i] = 1\n",
    "for i in range(0,length):\n",
    "    a[i] = 1 - a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(l):\n",
    "    mid = (len(l)-1)//2\n",
    "    if len(l) == 1 or (len(l) == 2 and l[0]!=l[1]):\n",
    "        return 0\n",
    "    if len(l) == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return x(l[:mid+1]) + x(l[mid:mid+2]) + x(l[mid+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergingTwoSortedArrays(a1,a2):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    a3 = []\n",
    "    while(i<len(a1) and j<len(a2)):\n",
    "        if a1[i]>a2[j]:\n",
    "            a3.append(a2[j])\n",
    "            j+=1\n",
    "        else:\n",
    "            a3.append(a1[i])\n",
    "            i+=1\n",
    "    if i<len(a1):\n",
    "        return a3 + a1[i:]\n",
    "    else:\n",
    "        return a3 + a2[j:]\n",
    "\n",
    "def mergeSorted(arr):\n",
    "    '''returns sorted array'''\n",
    "    low,high = 0,len(arr)\n",
    "    mid = (low+high)//2\n",
    "    if len(arr) == 1:\n",
    "        return arr\n",
    "    else:\n",
    "        return mergingTwoSortedArrays(mergeSorted(arr[low:mid]),mergeSorted(arr[mid:high]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [5,2,3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergeSorted(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# // counting no of pairs adding up to a numbet\n",
    "arr = [72,18,4,33,82,68,32,67,55,57,16,92,29,40,79,3,96,4,6, 87, 54, 33, 98 ,2 ,51 ,12 ,16 ,5 ,4,6 ]\n",
    "def getPairsCount(arr,k):\n",
    "        count = 0\n",
    "        arr = [arr[i] for i in range(len(arr)) if arr[i]<=k]\n",
    "        arr = sorted(arr)\n",
    "        if len(arr) == 0 or arr[0]>k:\n",
    "            return 0\n",
    "        for i in range(len(arr)):\n",
    "            for j in range(i+1,len(arr)):\n",
    "                if arr[i] + arr[j]>k:\n",
    "                    continue\n",
    "                if arr[i] + arr[j] == k:\n",
    "                    count+=1\n",
    "        return count\n",
    "print(getPairsCount(arr,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3, 4, 5, 5, 5, 5]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,1,2,3,4,5,5,5,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12212/1251893279.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     model_selection=0, min_detection_confidence=0.5) as face_detection:\n\u001b[0;32m     30\u001b[0m   \u001b[1;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m       \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ignoring empty camera frame.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "with mp_face_detection.FaceDetection(\n",
    "    model_selection=1, min_detection_confidence=0.5) as face_detection:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "    results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Draw face detections of each face.\n",
    "    if not results.detections:\n",
    "      continue\n",
    "    annotated_image = image.copy()\n",
    "    for detection in results.detections:\n",
    "      print('Nose tip:')\n",
    "      print(mp_face_detection.get_key_point(\n",
    "          detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))\n",
    "      mp_drawing.draw_detection(annotated_image, detection)\n",
    "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_face_detection.FaceDetection(\n",
    "    model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(image)\n",
    "\n",
    "    # Draw the face detection annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.detections:\n",
    "      for detection in results.detections:\n",
    "        mp_drawing.draw_detection(image, detection)\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.8.9.1-cp39-cp39-win_amd64.whl (48.5 MB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (3.19.1)\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.5.5.64-cp36-abi3-win_amd64.whl (42.2 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: six in c:\\users\\maths\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Installing collected packages: opencv-contrib-python, mediapipe\n",
      "Successfully installed mediapipe-0.8.9.1 opencv-contrib-python-4.5.5.64\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.8.9.1-cp39-cp39-win_amd64.whl (48.5 MB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.5.5.64-cp36-abi3-win_amd64.whl (42.2 MB)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (3.19.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\maths\\anaconda3\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: six in c:\\users\\maths\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maths\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Installing collected packages: opencv-contrib-python, mediapipe\n",
      "Successfully installed mediapipe-0.8.9.1 opencv-contrib-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12212/4027996830.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_face_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mface_landmarks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_face_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         mp_drawing.draw_landmarks(\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mlandmark_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mface_landmarks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\drawing_utils.py\u001b[0m in \u001b[0;36mdraw_landmarks\u001b[1;34m(image, landmark_list, connections, landmark_drawing_spec, connection_drawing_spec)\u001b[0m\n\u001b[0;32m    179\u001b[0m         drawing_spec = connection_drawing_spec[connection] if isinstance(\n\u001b[0;32m    180\u001b[0m             connection_drawing_spec, Mapping) else connection_drawing_spec\n\u001b[1;32m--> 181\u001b[1;33m         cv2.line(image, idx_to_coordinates[start_idx],\n\u001b[0m\u001b[0;32m    182\u001b[0m                  \u001b[0midx_to_coordinates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrawing_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                  drawing_spec.thickness)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print and draw face mesh landmarks on the image.\n",
    "    if not results.multi_face_landmarks:\n",
    "      continue\n",
    "    annotated_image = image.copy()\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "      print('face_landmarks:', face_landmarks)\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_tesselation_style())\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_contours_style())\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_iris_connections_style())\n",
    "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "# For webcam input:\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # Draw the face mesh annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_face_landmarks:\n",
    "      for face_landmarks in results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_tesselation_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_iris_connections_style())\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    cv2.imshow('MediaPipe Face Mesh', cv2.flip(image, 1))\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model to C:\\Users\\maths\\anaconda3\\lib\\site-packages\\mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17224/2189184865.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# Draw the pose annotation on the image.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\pose.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \"\"\"\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    332\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     \u001b[1;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;31m# output stream names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "BG_COLOR = (192, 192, 192) # gray\n",
    "with mp_pose.Pose(\n",
    "    static_image_mode=True,\n",
    "    model_complexity=2,\n",
    "    enable_segmentation=True,\n",
    "    min_detection_confidence=0.5) as pose:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    image_height, image_width, _ = image.shape\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if not results.pose_landmarks:\n",
    "      continue\n",
    "    print(\n",
    "        f'Nose coordinates: ('\n",
    "        f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * image_width}, '\n",
    "        f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image_height})'\n",
    "    )\n",
    "\n",
    "    annotated_image = image.copy()\n",
    "    # Draw segmentation on the image.\n",
    "    # To improve segmentation around boundaries, consider applying a joint\n",
    "    # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
    "    condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "    bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "    bg_image[:] = BG_COLOR\n",
    "    annotated_image = np.where(condition, annotated_image, bg_image)\n",
    "    # Draw pose landmarks on the image.\n",
    "    mp_drawing.draw_landmarks(\n",
    "        annotated_image,\n",
    "        results.pose_landmarks,\n",
    "        mp_pose.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "    # Plot pose world landmarks.\n",
    "    mp_drawing.plot_landmarks(\n",
    "        results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as pose:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image)\n",
    "\n",
    "    # Draw the pose annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.pose_landmarks,\n",
    "        mp_pose.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    cv2.imshow('MediaPipe Pose', cv2.flip(image, 1))\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_inversion_1(arr1, arr2):\n",
    "    '''Merges sorted arrays and returns a sorted array '''\n",
    "    i = 0\n",
    "    j = 0\n",
    "    count = 0\n",
    "    while(i < len(arr1) and j<len(arr2)):\n",
    "        if arr1[i]<=arr2[j]:\n",
    "            i+=1\n",
    "        else:\n",
    "            count = count + (len(arr1) - i);\n",
    "            j = j+1\n",
    "    return count\n",
    "# def mergeSorted(arr):\n",
    "#     '''returns sorted array'''\n",
    "#     low,high = 0,len(arr)\n",
    "#     mid = (low+high)//2\n",
    "#     if len(arr) == 1:\n",
    "#         return arr\n",
    "#     else:\n",
    "#         a= count_inversion(arr[low:mid])\n",
    "#         b= mergeSorted(arr[mid:high])\n",
    "#         return merger(a,b)\n",
    "\n",
    "# print(mergeSorted([3,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n"
     ]
    }
   ],
   "source": [
    "def count_inversion(arr):\n",
    "    if len(arr) == 1:\n",
    "        return 0\n",
    "    if len(arr) == 2 and arr[0]>arr[1]:\n",
    "        return 1\n",
    "    mid  = len(arr)//2\n",
    "    arr1 =arr[:mid]\n",
    "    arr2 =arr[mid:]\n",
    "    return count_inversion(arr1) + count_inversion(arr2) + count_inversion_1(sorted(arr1),sorted(arr2))\n",
    "print(count_inversion([468 ,335, 1 ,170 ,225 ,479, 359 ,463 ,465 ,206 ,146, 282 ,328, 462 ,492 ,496, 443 ,328 ,437 ,392 ,105 ,403 ,154 ,293 ,383 ,422 ,217 ,219 ,396 ,448 ,227 ,272 ,39 ,370 ,413 ,168 ,300 ,36 ,395 ,204 ,312 ,323]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "[6,-3,-10,1,-2,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c154fd27a2caa632c8148fc7812a9f55372d48417e207b9fb7b68c01ff3642c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
